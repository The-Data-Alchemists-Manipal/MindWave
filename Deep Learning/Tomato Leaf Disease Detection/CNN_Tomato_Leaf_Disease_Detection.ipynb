{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets,layers,models\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import ipywidgets as widgets\n",
    "import io\n",
    "from PIL import Image\n",
    "import tqdm\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "Y=[]\n",
    "size=255\n",
    "folder='/content/drive/MyDrive/Ml/tomato leaf disease classification/tomato/val'\n",
    "labels=['Tomato___Bacterial_spot','Tomato___Early_blight','Tomato___healthy','Tomato___Late_blight','Tomato___Leaf_Mold','Tomato___Septoria_leaf_spot','Tomato___Spider_mites Two-spotted_spider_mite','Tomato___Target_Spot','Tomato___Tomato_mosaic_virus','Tomato___Tomato_Yellow_Leaf_Curl_Virus']\n",
    "\n",
    "for i in labels:\n",
    "  folder_path=os.path.join(folder,i)\n",
    " \n",
    "  for j in os.listdir(folder_path):\n",
    "    \n",
    "    img=cv2.imread(os.path.join(folder_path,j))\n",
    "    img=cv2.resize(img,(size,size))\n",
    "    X.append(img)\n",
    "    Y.append(i)\n",
    "\n",
    "    \n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "\n",
    "X,Y = shuffle(X,Y,random_state=0)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m sklearn.model_selection import  train_test_split\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.1,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_new = []\n",
    "for i in Y_train:\n",
    "    Y_train_new.append(labels.index(i))\n",
    "Y_train=Y_train_new\n",
    "Y_train = tf.keras.utils.to_categorical(Y_train)\n",
    "\n",
    "Y_test_new = []\n",
    "for i in Y_test:\n",
    "    Y_test_new.append(labels.index(i))\n",
    "Y_test=Y_test_new\n",
    "Y_test = tf.keras.utils.to_categorical(Y_test)\n",
    "\n",
    "Y_train_new=np.array(Y_train_new)\n",
    "Y_test_new=np.array(Y_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train/255\n",
    "X_test=X_test/255\n",
    "\n",
    "\n",
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=models.Sequential([\n",
    "    #cnn\n",
    "    layers.Conv2D(filters=23,kernel_size=(3,3),activation='relu',input_shape=(255,255,3)),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "\n",
    "     layers.Conv2D(filters=50,kernel_size=(3,3),activation='relu',input_shape=(255,255,3)),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    #dense\n",
    "    layers.Flatten(),\n",
    "   \n",
    "    \n",
    "    layers.Dense(50,activation='relu'),\n",
    "    layers.Dense(25,activation='relu'),\n",
    "    layers.Dense(10,activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train ,Y_train_new,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test,Y_test_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(model,\"trainedModel.pkl\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
=======
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets,layers,models\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import ipywidgets as widgets\n",
    "import io\n",
    "from PIL import Image\n",
    "import tqdm\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "Y=[]\n",
    "size=255\n",
    "folder='/content/drive/MyDrive/Ml/tomato leaf disease classification/tomato/val'\n",
    "labels=['Tomato___Bacterial_spot','Tomato___Early_blight','Tomato___healthy','Tomato___Late_blight','Tomato___Leaf_Mold','Tomato___Septoria_leaf_spot','Tomato___Spider_mites Two-spotted_spider_mite','Tomato___Target_Spot','Tomato___Tomato_mosaic_virus','Tomato___Tomato_Yellow_Leaf_Curl_Virus']\n",
    "\n",
    "for i in labels:\n",
    "  folder_path=os.path.join(folder,i)\n",
    " \n",
    "  for j in os.listdir(folder_path):\n",
    "    \n",
    "    img=cv2.imread(os.path.join(folder_path,j))\n",
    "    img=cv2.resize(img,(size,size))\n",
    "    X.append(img)\n",
    "    Y.append(i)\n",
    "\n",
    "    \n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "\n",
    "X,Y = shuffle(X,Y,random_state=0)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m sklearn.model_selection import  train_test_split\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.1,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_new = []\n",
    "for i in Y_train:\n",
    "    Y_train_new.append(labels.index(i))\n",
    "Y_train=Y_train_new\n",
    "Y_train = tf.keras.utils.to_categorical(Y_train)\n",
    "\n",
    "Y_test_new = []\n",
    "for i in Y_test:\n",
    "    Y_test_new.append(labels.index(i))\n",
    "Y_test=Y_test_new\n",
    "Y_test = tf.keras.utils.to_categorical(Y_test)\n",
    "\n",
    "Y_train_new=np.array(Y_train_new)\n",
    "Y_test_new=np.array(Y_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train/255\n",
    "X_test=X_test/255\n",
    "\n",
    "\n",
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=models.Sequential([\n",
    "    #cnn\n",
    "    layers.Conv2D(filters=23,kernel_size=(3,3),activation='relu',input_shape=(255,255,3)),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "\n",
    "     layers.Conv2D(filters=50,kernel_size=(3,3),activation='relu',input_shape=(255,255,3)),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    #dense\n",
    "    layers.Flatten(),\n",
    "   \n",
    "    \n",
    "    layers.Dense(50,activation='relu'),\n",
    "    layers.Dense(25,activation='relu'),\n",
    "    layers.Dense(10,activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train ,Y_train_new,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test,Y_test_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(model,\"trainedModel.pkl\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

