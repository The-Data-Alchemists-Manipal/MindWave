{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from transformers import TFBertModel, BertTokenizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "data = pd.read_json(\"/kaggle/input/imdb-spoiler-dataset/IMDB_reviews.json\", lines=True)\n",
    "labels = data.is_spoiler.values\n",
    "sentences = data.review_text.values\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_TRAINED_MODEL_NAME = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME,do_lower_case = True)\n",
    "\n",
    "def encoder(sentences):\n",
    "  ids = []\n",
    "  for sentence in sentences:\n",
    "    encoding = tokenizer.encode_plus(\n",
    "    sentence,\n",
    "    max_length=16,\n",
    "    truncation = True,\n",
    "    add_special_tokens=True,\n",
    "    return_token_type_ids=False,\n",
    "    pad_to_max_length=True,\n",
    "    return_attention_mask=False)\n",
    "    ids.append(encoding['input_ids'])\n",
    "  return ids\n",
    "\n",
    "#Train test split\n",
    "train_sents,test_sents, train_labels, test_labels  = train_test_split(sentences,labels,test_size=0.15)\n",
    "\n",
    "train_ids = encoder(train_sents)\n",
    "test_ids = encoder(test_sents) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = tf.convert_to_tensor(train_ids)\n",
    "test_ids = tf.convert_to_tensor(test_ids)\n",
    "test_labels = tf.convert_to_tensor(test_labels)\n",
    "train_labels = tf.convert_to_tensor(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_encoder = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "input_word_ids = tf.keras.Input(shape=(16,), dtype=tf.int32, name=\"input_word_ids\")  \n",
    "embedding = bert_encoder([input_word_ids])\n",
    "dense = tf.keras.layers.Lambda(lambda seq: seq[:, 0, :])(embedding[0])\n",
    "dense = tf.keras.layers.Dense(128, activation='relu')(dense)\n",
    "dense = tf.keras.layers.Dropout(0.2)(dense)   \n",
    "output = tf.keras.layers.Dense(1, activation='sigmoid')(dense)    \n",
    "\n",
    "model = tf.keras.Model(inputs=[input_word_ids], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(tf.keras.optimizers.Adam(1e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x = train_ids, y = train_labels, epochs = 5, verbose = 1, batch_size = 32, validation_data = (test_ids, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graphs(history, string):\n",
    "  plt.plot(history.history[string])\n",
    "  plt.plot(history.history['val_'+string])\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(string)\n",
    "  plt.legend([string, 'val_'+string])\n",
    "  plt.show()\n",
    "\n",
    "plot_graphs(history, 'accuracy')\n",
    "plot_graphs(history, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Predict labels for test data\n",
    "y_pred = model.predict(test_ids)\n",
    "y_pred = np.round(y_pred).flatten()\n",
    "\n",
    "# Compute precision, recall and F1 score\n",
    "report = classification_report(test_labels, y_pred)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
