{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7838dff8",
   "metadata": {},
   "source": [
    "# LOAN REPAYMENT\n",
    "\n",
    "## The Data\n",
    "\n",
    "We will be using a subset of the LendingClub DataSet obtained from Kaggle: https://www.kaggle.com/wordsforthewise/lending-club\n",
    "\n",
    "LendingClub is a US peer-to-peer lending company, headquartered in San Francisco, California.[3] It was the first peer-to-peer lender to register its offerings as securities with the Securities and Exchange Commission (SEC), and to offer loan trading on a secondary market. LendingClub is the world's largest peer-to-peer lending platform.\n",
    "\n",
    "### Our Goal\n",
    "\n",
    "Given historical data on loans given out with information on whether or not the borrower defaulted (charge-off), can we build a model thatcan predict wether or nor a borrower will pay back their loan? This way in the future when we get a new potential customer we can assess whether or not they are likely to pay back the loan. Keep in mind classification metrics when evaluating the performance of your model!\n",
    "\n",
    "The \"loan_status\" column contains our label.\n",
    "\n",
    "### Data Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdeb6fa",
   "metadata": {},
   "source": [
    "----\n",
    "-----\n",
    "There are many LendingClub data sets on Kaggle. Here is the information on this particular data set:\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>LoanStatNew</th>\n",
    "      <th>Description</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>0</th>\n",
    "      <td>loan_amnt</td>\n",
    "      <td>The listed amount of the loan applied for by the borrower. If at some point in time, the credit department reduces the loan amount, then it will be reflected in this value.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>term</td>\n",
    "      <td>The number of payments on the loan. Values are in months and can be either 36 or 60.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2</th>\n",
    "      <td>int_rate</td>\n",
    "      <td>Interest Rate on the loan</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>3</th>\n",
    "      <td>installment</td>\n",
    "      <td>The monthly payment owed by the borrower if the loan originates.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>4</th>\n",
    "      <td>grade</td>\n",
    "      <td>LC assigned loan grade</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>5</th>\n",
    "      <td>sub_grade</td>\n",
    "      <td>LC assigned loan subgrade</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>6</th>\n",
    "      <td>emp_title</td>\n",
    "      <td>The job title supplied by the Borrower when applying for the loan.*</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>7</th>\n",
    "      <td>emp_length</td>\n",
    "      <td>Employment length in years. Possible values are between 0 and 10 where 0 means less than one year and 10 means ten or more years.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>8</th>\n",
    "      <td>home_ownership</td>\n",
    "      <td>The home ownership status provided by the borrower during registration or obtained from the credit report. Our values are: RENT, OWN, MORTGAGE, OTHER</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>9</th>\n",
    "      <td>annual_inc</td>\n",
    "      <td>The self-reported annual income provided by the borrower during registration.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>10</th>\n",
    "      <td>verification_status</td>\n",
    "      <td>Indicates if income was verified by LC, not verified, or if the income source was verified</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>11</th>\n",
    "      <td>issue_d</td>\n",
    "      <td>The month which the loan was funded</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>12</th>\n",
    "      <td>loan_status</td>\n",
    "      <td>Current status of the loan</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>13</th>\n",
    "      <td>purpose</td>\n",
    "      <td>A category provided by the borrower for the loan request.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>14</th>\n",
    "      <td>title</td>\n",
    "      <td>The loan title provided by the borrower</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>15</th>\n",
    "      <td>zip_code</td>\n",
    "      <td>The first 3 numbers of the zip code provided by the borrower in the loan application.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>16</th>\n",
    "      <td>addr_state</td>\n",
    "      <td>The state provided by the borrower in the loan application</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>17</th>\n",
    "      <td>dti</td>\n",
    "      <td>A ratio calculated using the borrower’s total monthly debt payments on the total debt obligations, excluding mortgage and the requested LC loan, divided by the borrower’s self-reported monthly income.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>18</th>\n",
    "      <td>earliest_cr_line</td>\n",
    "      <td>The month the borrower's earliest reported credit line was opened</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>19</th>\n",
    "      <td>open_acc</td>\n",
    "      <td>The number of open credit lines in the borrower's credit file.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>20</th>\n",
    "      <td>pub_rec</td>\n",
    "      <td>Number of derogatory public records</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>21</th>\n",
    "      <td>revol_bal</td>\n",
    "      <td>Total credit revolving balance</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>22</th>\n",
    "      <td>revol_util</td>\n",
    "      <td>Revolving line utilization rate, or the amount of credit the borrower is using relative to all available revolving credit.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>23</th>\n",
    "      <td>total_acc</td>\n",
    "      <td>The total number of credit lines currently in the borrower's credit file</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>24</th>\n",
    "      <td>initial_list_status</td>\n",
    "      <td>The initial listing status of the loan. Possible values are – W, F</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>25</th>\n",
    "      <td>application_type</td>\n",
    "      <td>Indicates whether the loan is an individual application or a joint application with two co-borrowers</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>26</th>\n",
    "      <td>mort_acc</td>\n",
    "      <td>Number of mortgage accounts.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>27</th>\n",
    "      <td>pub_rec_bankruptcies</td>\n",
    "      <td>Number of public record bankruptcies</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "---\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0967041f",
   "metadata": {},
   "source": [
    "## Starter Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b82759a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e36d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_info = pd.read_csv(\"F:\\\\04- UDEMY COURSES\\\\02- Data Science\\\\Py_DS_ML_Bootcamp-master\\\\TensorFlow_FILES\\\\DATA\\\\lending_club_info.csv\", index_col='LoanStatNew')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91519b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_info.loc['revol_util']['Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ec845d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_info(col_name):\n",
    "    print(data_info.loc[col_name]['Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d8b11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_info('mort_acc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d5b07b",
   "metadata": {},
   "source": [
    "## Loading the data and other imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501ae3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829f1c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"F:\\\\04- UDEMY COURSES\\\\02- Data Science\\\\Py_DS_ML_Bootcamp-master\\\\TensorFlow_FILES\\\\DATA\\\\lending_club_loan_two.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a921a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c123040",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b5a836",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0192292f",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Section 1: Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb2a7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count PLot for the label - 'loan_status'\n",
    "df.loan_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b21166",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=df, x=df.loan_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d321b894",
   "metadata": {},
   "source": [
    "**TASK: Create a histogram of the loan_amnt column.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a325420",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "# df.loan_amnt.plot(kind = 'hist', bins=40)\n",
    "sns.histplot(data=df, x=df.loan_amnt, bins=40)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcf7c57",
   "metadata": {},
   "source": [
    "**Let's explore correlation between the continuous feature variables. Calculating the correlation between all continuous numeric variables using .corr() method.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f118d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656e755c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(df.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589fb005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most corealated features with \"loan_amnt\"\n",
    "df.corr()['loan_amnt'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65eade6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loan_amnt\n",
    "feat_info('loan_amnt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b768a2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loan_amnt.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd91e12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# installment\n",
    "feat_info('installment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90afa57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.installment.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680ba432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot for 'loan_amnt' v/s 'installment'\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.scatterplot(data=df, x=df.installment, y=df.loan_amnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9250e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# px.scatter(data_frame=df, x=df.loan_amnt, y=df.installment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0765c53",
   "metadata": {},
   "source": [
    "**Creating a boxplot showing the relationship between the loan_status and the Loan Amount.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7972db20",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df, x=df.loan_status, y=df.loan_amnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46078369",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(data_frame=df, x=df.loan_status, y=df.loan_amnt, color=df.loan_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71004e44",
   "metadata": {},
   "source": [
    "**Calculating the summary statistics for the loan amount, grouped by the loan_status.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305c54b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('loan_status')['loan_amnt'].describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3b4046",
   "metadata": {},
   "source": [
    "**Let's explore the Grade and SubGrade columns that LendingClub attributes to the loans. What are the unique possible grades and subgrades?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285fbbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grade\n",
    "feat_info('grade')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9a9564",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.grade.sort_values().unique())\n",
    "print()\n",
    "# or\n",
    "\n",
    "print(sorted(df.grade.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a942f3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub_grade\n",
    "feat_info('sub_grade')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6812bed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.sub_grade.sort_values().unique())\n",
    "print()\n",
    "\n",
    "# or\n",
    "print(sorted(df.sub_grade.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e21586",
   "metadata": {},
   "source": [
    "**Creating a countplot per grade.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457c9f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.countplot(data=df, x=df.grade, hue=df.loan_status)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49695fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24, 8))\n",
    "sub_grade_order = sorted(df.sub_grade.unique())\n",
    "sns.countplot(data=df, x=df.sub_grade, order=sub_grade_order, palette='coolwarm')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d68343",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24, 8))\n",
    "sub_grade_order = sorted(df.sub_grade.unique())\n",
    "sns.countplot(data=df, x=df.sub_grade, order=sub_grade_order, palette='coolwarm', hue=df.loan_status)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d75a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the rows having \"F\" or \"G\" as a grade\n",
    "f_and_g = df[(df['grade'] == 'F') | (df['grade'] == 'G')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5dc4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "subgrade_order = sorted(f_and_g.sub_grade.unique())\n",
    "sns.countplot(data=f_and_g, x=f_and_g.sub_grade, order=subgrade_order, hue=f_and_g.loan_status,)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26178656",
   "metadata": {},
   "source": [
    "**Creating a new column called 'load_repaid' which will contain a 1 if the loan status was \"Fully Paid\" and a 0 if it was \"Charged Off\".**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab16d932",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loan_status.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516ac425",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict1 = {'Fully Paid':1, 'Charged Off':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3b92e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['loan_repaid'] = df.loan_status.map(dict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518ba2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5247a5b",
   "metadata": {},
   "source": [
    "** Creating a bar plot showing the correlation of the numeric features to the new loan_repaid column. [Helpful Link](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.bar.html)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2eda9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()['loan_repaid'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5911ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()['loan_repaid'][:-1].sort_values(ascending=False).plot(kind='bar')\n",
    "plt.grid()\n",
    "\n",
    "# or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80621d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()['loan_repaid'].sort_values().drop('loan_repaid').plot(kind='bar')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1563864e",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# Section 2: Data PreProcessing\n",
    "\n",
    "**Section Goals: Remove or fill any missing data. Remove unnecessary or repetitive features. Convert categorical string features to dummy variables.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc522de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc1afc4",
   "metadata": {},
   "source": [
    "# Missing Data\n",
    "\n",
    "**Let's explore this missing data columns. We use a variety of factors to decide whether or not they would be useful, to see if we should keep, discard, or fill in the missing data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae2982b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4f3c03",
   "metadata": {},
   "source": [
    "**Creating a Series that displays the total count of missing values per column.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11735fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bf89ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of missing data\n",
    "df.isnull().sum() / len(df) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988f2c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# emp_title\n",
    "feat_info('emp_title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4530ae9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()['emp_title']/396030 * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d518d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# emp_length\n",
    "feat_info('emp_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9689dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()['emp_length']/396030 * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5229d566",
   "metadata": {},
   "source": [
    "**How many unique employment job titles are there?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6de71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.emp_title.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13afec5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.emp_title.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d0aedf",
   "metadata": {},
   "source": [
    "**Realistically there are too many unique job titles to try to convert this to a dummy variable feature. Let's remove that emp_title column.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca65110f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('emp_title', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883b5957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9107e520",
   "metadata": {},
   "source": [
    "**Creating a count plot of the emp_length feature column. Challenge: Sort the order of the values.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79be6755",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_order = sorted(df.emp_length.dropna().unique())\n",
    "\n",
    "sorted_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5027f5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_lenght_order = ['< 1 year',\n",
    "                    '1 year',\n",
    "                    '2 years',\n",
    "                    '3 years',\n",
    "                    '4 years',\n",
    "                    '5 years',\n",
    "                    '6 years',\n",
    "                    '7 years',\n",
    "                    '8 years',\n",
    "                    '9 years',\n",
    "                    '10+ years']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b37302",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,8))\n",
    "sns.countplot(data=df, x=df.emp_length, order=emp_lenght_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ddb334",
   "metadata": {},
   "source": [
    "**Ploting out the countplot with a hue separating Fully Paid vs Charged Off**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c77eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,8))\n",
    "sns.countplot(data=df, x=df.emp_length, order=emp_lenght_order, hue='loan_status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c268939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charged Off Details\n",
    "emp_co = df[df['loan_status'] == 'Charged Off'].groupby('emp_length').count()['loan_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f718a15f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "emp_co"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df1db6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully Paid Details\n",
    "emp_fp = df[df['loan_status'] == 'Fully Paid'].groupby('emp_length').count()['loan_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d469acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49d8f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_len = emp_co / emp_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bb9022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentage\n",
    "emp_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1efca0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratio of emp_co\n",
    "emp_ratio = emp_co / (emp_co + emp_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e3f4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for percentage\n",
    "emp_len.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee35b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for emp_co ratio\n",
    "emp_ratio.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1544802d",
   "metadata": {},
   "source": [
    "**Charge off rates are extremely similar across all employment lengths. Lt's drop the emp_length column.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3d1dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('emp_length', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdefe67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a34ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50f5f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_info('purpose')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb46348",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_info('title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f0a8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.title.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071d81d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.purpose.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9555c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As both the columns 'title' and 'purpose' have same information, so we can drop one of the column\n",
    "df = df.drop('title', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b761eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_info('mort_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c5524c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mort_acc.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943ca01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Correlation with the mort_acc column:\")\n",
    "df.corr()['mort_acc'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17a9015",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_info('total_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995f418e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean of mort_acc column per total_acc:\")\n",
    "df.groupby('total_acc').mean()['mort_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97469cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_acc_avg = df.groupby('total_acc').mean()['mort_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c025f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_acc_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5026b156",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_acc_avg[100.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf4041d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_mort_acc(total_acc, mort_acc):\n",
    "    '''\n",
    "    Accepts the total_acc and mort_acc values for the row.\n",
    "    Checks if the mort_acc is NaN , if so, it returns the avg mort_acc value\n",
    "    for the corresponding total_acc value for that row.\n",
    "    \n",
    "    total_acc_avg here should be a Series or dictionary containing the mapping of the\n",
    "    groupby averages of mort_Acc per total_Acc values.\n",
    "    '''\n",
    "    \n",
    "    if np.isnan(mort_acc):\n",
    "        return total_acc_avg[total_acc]\n",
    "    else:\n",
    "        return mort_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393eea15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mort_acc'] = df.apply(lambda x: fill_mort_acc(x['total_acc'], x['mort_acc']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e395d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63f5852",
   "metadata": {},
   "source": [
    "**revol_util and the pub_rec_bankruptcies have missing data points, but they account for less than 0.5% of the total data. Let's remove the rows that are missing those values in those columns with dropna().**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce114e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840f8f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec6425d",
   "metadata": {},
   "source": [
    "## Categorical Variables and Dummy Variables\n",
    "\n",
    "\n",
    "**List all the columns that are currently non-numeric. [Helpful Link](https://stackoverflow.com/questions/22470690/get-list-of-pandas-dataframe-columns-based-on-data-type)**\n",
    "\n",
    "[Another very useful method call](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.select_dtypes.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa57f55b",
   "metadata": {},
   "source": [
    "### .select_dtypes():\n",
    "- Return a subset of the DataFrame's columns based on the column dtypes.\n",
    "\n",
    "\n",
    "- **Parameters:**\n",
    "    - **include, exclude** : scalar or list-like\n",
    "        - A selection of dtypes or strings to be included/excluded. At least one of these parameters must be supplied.\n",
    "        \n",
    "        \n",
    "        - To select all numeric types, use np.number or 'number'\n",
    "        - To select strings you must use the object dtype, but note that this will return all object dtype columns\n",
    "        - See the numpy dtype hierarchy\n",
    "        - To select datetimes, use np.datetime64, 'datetime' or 'datetime64'\n",
    "        - To select timedeltas, use np.timedelta64, 'timedelta' or 'timedelta64'\n",
    "        - To select Pandas categorical dtypes, use 'category'\n",
    "        - To select Pandas datetimetz dtypes, use 'datetimetz' (new in 0.20.0) or 'datetime64[ns, tz]'\n",
    "        \n",
    "        \n",
    " #### Syntax:\n",
    " - **df.select_dtypes(include=None, exclude=None)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdafe735",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select_dtypes(exclude='number').columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27396fc5",
   "metadata": {},
   "source": [
    "---\n",
    "**Let's now go through all the string features to see what we should do with them.**\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### term feature\n",
    "\n",
    "**Converting the term feature into either a 36 or 60 integer numeric data type using .apply() or .map().**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db07125",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.term.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7885d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or just use .map()\n",
    "df['term'] = df.term.apply(lambda term: int(term[:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9d4c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.term.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c69a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3876daa",
   "metadata": {},
   "source": [
    "### grade feature\n",
    "\n",
    "**We already know grade is part of sub_grade, so just drop the grade feature.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7552afb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.grade.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7873c766",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('grade', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b05e22",
   "metadata": {},
   "source": [
    "**Converting the subgrade into dummy variables. Then concatenate these new columns to the original dataframe. Remember to drop the original subgrade column and to add drop_first=True to your get_dummies call.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58bf326",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sub_grade.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed5d4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "subgrade_dummies = pd.get_dummies(df.sub_grade,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c05e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding 'subgrade_dummies' into data set\n",
    "df = pd.concat([df, subgrade_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f6dce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('sub_grade', axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528ccd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select_dtypes(include='object').columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a78bd4e",
   "metadata": {},
   "source": [
    "### verification_status, application_type,initial_list_status,purpose \n",
    "**Converting these columns: ['verification_status', 'application_type','initial_list_status','purpose'] into dummy variables and concatenate them with the original dataframe. Remember to set drop_first=True and to drop the original columns.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83757554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verification_status\n",
    "df.verification_status.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0eff74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# application_type\n",
    "df.application_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd6b5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_list_status\n",
    "df.initial_list_status.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94f0c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# purpose\n",
    "df.purpose.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03705169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting ['verification_status', 'application_type','initial_list_status','purpose'] into dummy variables together\n",
    "dummies = pd.get_dummies(df[['verification_status', 'application_type', 'initial_list_status', 'purpose']], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f2a721",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df8d0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['verification_status', 'application_type', 'initial_list_status', 'purpose'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a311653a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b922242b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa053b2c",
   "metadata": {},
   "source": [
    "### home_ownership\n",
    "**Review the value_counts for the home_ownership column.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08deb606",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.home_ownership.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f923301e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['home_ownership'] = df.home_ownership.replace(to_replace=['NONE', 'ANY'], value='OTHER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cad3a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.home_ownership.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b28f209",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(df['home_ownership'], drop_first=True)\n",
    "df = df.drop('home_ownership', axis=1)\n",
    "df = pd.concat([df, dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0846876b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bab952",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ea5e17",
   "metadata": {},
   "source": [
    "### address\n",
    "**Let's feature engineer a zip code column from the address in the data set. Creating a column called 'zip_code' that extracts the zip code from the address column.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf0d8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.address.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1095b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['zip_code'] = df.address.apply(lambda address: address[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbd2558",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.zip_code.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f16f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(df['zip_code'], drop_first=True)\n",
    "df = df.drop(['zip_code', 'address'], axis=1)\n",
    "df = pd.concat([df, dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a971fcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7391bbef",
   "metadata": {},
   "source": [
    "### issue_d \n",
    "\n",
    "**This would be data leakage, we wouldn't know beforehand whether or not a loan would be issued when using our model, so in theory we wouldn't have an issue_date, drop this feature.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a45b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.issue_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db3eb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('issue_d', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c948dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52de4a6",
   "metadata": {},
   "source": [
    "### earliest_cr_line\n",
    "**This appears to be a historical time stamp feature. Extract the year from this feature using a .apply function, then convert it to a numeric feature. Set this new data to a feature column called 'earliest_cr_year'.Then drop the earliest_cr_line feature.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e0dd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_info('earliest_cr_line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431fbe10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.earliest_cr_line.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd00cdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting earliest_cr_line's 'year'\n",
    "df['earliest_cr_year'] = df.earliest_cr_line.apply(lambda year: int(year[-4:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4bab60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.earliest_cr_year.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b5442a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('earliest_cr_line', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25a2edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select_dtypes(include='object').columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d80cc12",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d9096b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742f808f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('loan_status', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e62cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('loan_repaid', axis=1).values\n",
    "y = df.loan_repaid.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a75138a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5c0f34",
   "metadata": {},
   "source": [
    "## Normalizing the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacfa59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0827c207",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2aa00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83aed9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab51aa1",
   "metadata": {},
   "source": [
    "# Creating the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab45497",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.constraints import max_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a78cfa",
   "metadata": {},
   "source": [
    "**Building a sequential model to will be trained on the data. You have unlimited options here, but here is what the solution uses: a model that goes 78 --> 39 --> 19--> 1 output neuron.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf4e66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# layer 1 / Input Layer\n",
    "model.add(Dense(units=78, activation='relu'))\n",
    "model.add(Dropout(rate=0.2))\n",
    "\n",
    "# Layer 2 / hidden Layer 1\n",
    "model.add(Dense(units=39, activation='relu'))\n",
    "model.add(Dropout(rate=0.2))\n",
    "\n",
    "# Layer 3 / hidden layer 2\n",
    "model.add(Dense(units=19, activation='relu'))\n",
    "model.add(Dropout(rate=0.2))\n",
    "\n",
    "# Layer 4 / output layer\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6044934a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=X_train,\n",
    "          y=y_train,\n",
    "          batch_size=256,\n",
    "          validation_data=(X_test, y_test),\n",
    "          epochs=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd4bb31",
   "metadata": {},
   "source": [
    "# Section 3: Evaluating Model Performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c415fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a9c89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e356db05",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1c5925",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb0b5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = (model.predict(X_test) > (0.5)).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643f5b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fb84fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f5d549",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44a3262",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86c5b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe6dca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "display = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=['Charged Off', 'Repaid'])\n",
    "display.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54abdf7",
   "metadata": {},
   "source": [
    "**Save your model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cc171b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45b1741",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"full_data_project_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16484912",
   "metadata": {},
   "source": [
    "**TASK: Given the customer below, would you offer this person a loan?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a452ced6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(101)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceba26ea",
   "metadata": {},
   "source": [
    "#### random.randint(a, b):\n",
    "\n",
    "- Return random integer in range [a, b], including both end points\n",
    "\n",
    "\n",
    "- **Syntax:** \n",
    "    - **random.randint(a, b)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6c0a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_ind = random.randint(0, len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd27b99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_customer = df.drop('loan_repaid', axis=1).iloc[random_ind]\n",
    "new_customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dfb642",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_customer = scaler.transform(new_customer.values.reshape(1,78))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de69f63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting On A New DataSet\n",
    "(model.predict(new_customer) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fc8d20",
   "metadata": {},
   "source": [
    "**Now check, did this person actually end up paying back their loan?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f5c01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[random_ind]['loan_repaid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e407cff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59be394e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1479c003",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b0a971",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbf9e9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
