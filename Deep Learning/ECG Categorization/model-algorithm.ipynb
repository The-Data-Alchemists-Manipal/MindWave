{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from keras import layers\n",
    "from keras.layers import Dense, Activation, Flatten, Convolution1D, Dropout,MaxPooling1D\n",
    "from keras.layers import Input, Dense, Dropout, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, Embedding, Add\n",
    "from keras.layers import Conv1D, GlobalAveragePooling1D, AveragePooling2D, MaxPooling2D, MaxPool1D, ZeroPadding1D, GlobalMaxPooling2D, GlobalAveragePooling2D, LSTM, SpatialDropout1D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import plot_model\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from keras.callbacks import ReduceLROnPlateau , EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam \n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mit_test_data = pd.read_csv('/kaggle/input/heartbeat/mitbih_test.csv', header=None)\n",
    "mit_train_data = pd.read_csv('/kaggle/input/heartbeat/mitbih_train.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mit_train_data.shape)\n",
    "print(mit_test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mit_train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = mit_train_data.iloc[: , :-1], mit_train_data.iloc[: , -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX, testy = mit_test_data.iloc[: , :-1], mit_test_data.iloc[: , -1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mit_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "testy = to_categorical(testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X shape=\" +str(x_train.shape))\n",
    "print(\"y shape=\" +str(y_train.shape))\n",
    "\n",
    "print(\"testX shape=\" +str(testX.shape))\n",
    "print(\"testy shape=\" +str(testy.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_model = Sequential()\n",
    "ann_model.add(Dense(64, activation='relu', input_shape=(187,)))\n",
    "ann_model.add(Dropout(0.2))\n",
    "ann_model.add(Dense(64, activation='relu'))\n",
    "ann_model.add(Dropout(0.2))\n",
    "ann_model.add(Dense(32, activation='relu'))\n",
    "ann_model.add(Dropout(0.2))\n",
    "ann_model.add(Dense(32, activation='relu'))\n",
    "ann_model.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor=\"val_loss\", mode=\"min\", verbose=1, patience=5)\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "tf.keras.utils.plot_model(ann_model, to_file='ann_model.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = ann_model.fit(x_train, y_train,batch_size=128,\n",
    "epochs=200,\n",
    "verbose=1,\n",
    "validation_data = (testX, testy),\n",
    "callbacks = [learning_rate_reduction,es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,1)\n",
    "ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "ax[0].plot(history.history['val_loss'], color='orange', label=\"validation loss\",axes =ax[0])\n",
    "legend = ax[0].legend(loc='best', shadow=True)\n",
    "\n",
    "ax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "ax[1].plot(history.history['val_accuracy'], color='orange',label=\"Validation accuracy\")\n",
    "legend = ax[1].legend(loc='best', shadow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution1D(filters=32, kernel_size=5, strides=1 , input_shape=(187,1)))\n",
    "model.add(Convolution1D(filters=32, kernel_size=5, strides=1, padding='same' , activation='relu'))\n",
    "model.add(Convolution1D(filters=32, kernel_size=5, strides=1, padding='same' , activation = 'relu'))\n",
    "model.add(MaxPooling1D(pool_size=5, strides=2))\n",
    "\n",
    "model.add(Convolution1D(filters=32, kernel_size=5, strides=1, padding='same' , activation='relu'))\n",
    "model.add(Convolution1D(filters=32, kernel_size=5, strides=1, padding='same' , activation = 'relu'))\n",
    "model.add(MaxPooling1D(pool_size=5, strides=2))\n",
    "\n",
    "model.add(Convolution1D(filters=32, kernel_size=5, strides=1, padding='same' , activation='relu'))\n",
    "model.add(Convolution1D(filters=32, kernel_size=5, strides=1, padding='same' , activation = 'relu'))\n",
    "model.add(MaxPooling1D(pool_size=5, strides=2))\n",
    "\n",
    "model.add(Convolution1D(filters=32, kernel_size=5, strides=1, padding='same' , activation='relu'))\n",
    "model.add(Convolution1D(filters=32, kernel_size=5, strides=1, padding='same' , activation = 'relu'))\n",
    "model.add(MaxPooling1D(pool_size=5, strides=2))\n",
    "\n",
    "model.add(Convolution1D(filters=32, kernel_size=5, strides=1, padding='same' , activation='relu'))\n",
    "model.add(Convolution1D(filters=32, kernel_size=5, strides=1, padding='same' , activation = 'relu'))\n",
    "model.add(MaxPooling1D(pool_size=5, strides=2))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "tf.keras.utils.plot_model(ann_model, to_file='model.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor=\"val_loss\", mode=\"min\", verbose=1, patience=10)\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train,batch_size=128,\n",
    "epochs=200,\n",
    "verbose=1,\n",
    "validation_data = (testX, testy),\n",
    "callbacks = [learning_rate_reduction,es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss and accuracy curves for training and validation \n",
    "fig, ax = plt.subplots(2,1)\n",
    "ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "ax[0].plot(history.history['val_loss'], color='orange', label=\"validation loss\",axes =ax[0])\n",
    "legend = ax[0].legend(loc='best', shadow=True)\n",
    "\n",
    "ax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "ax[1].plot(history.history['val_accuracy'], color='orange',label=\"Validation accuracy\")\n",
    "legend = ax[1].legend(loc='best', shadow=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
