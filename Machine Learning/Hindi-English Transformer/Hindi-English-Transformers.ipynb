{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Download Dataset from - https://www.kaggle.com/datasets/aiswaryaramachandran/hindienglish-corpora"
      ],
      "metadata": {
        "id": "EgkR_WbTfcJP"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "OqPY7c1clG-7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "metadata": {
        "id": "_TE_gHW_lRzi"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('Hindi_English_Truncated_Corpus.csv')"
      ],
      "metadata": {
        "id": "A_yr4K3elYKk"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "VkmVI0bFlawW",
        "outputId": "7bc01805-f50b-4dda-df02-66a6ac98cd48"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      source                                   english_sentence  \\\n",
              "0        ted  politicians do not have permission to do what ...   \n",
              "1        ted         I'd like to tell you about one such child,   \n",
              "2  indic2012  This percentage is even greater than the perce...   \n",
              "3        ted  what we really mean is that they're bad at not...   \n",
              "4  indic2012  .The ending portion of these Vedas is called U...   \n",
              "5      tides  The then Governor of Kashmir resisted transfer...   \n",
              "6  indic2012  In this lies the circumstances of people befor...   \n",
              "7        ted   And who are we to say, even, that they are wrong   \n",
              "8  indic2012  “”Global Warming“” refer to warming caused in ...   \n",
              "9      tides  You may want your child to go to a school that...   \n",
              "\n",
              "                                      hindi_sentence  \n",
              "0  राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...  \n",
              "1  मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...  \n",
              "2   यह प्रतिशत भारत में हिन्दुओं प्रतिशत से अधिक है।  \n",
              "3     हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते  \n",
              "4        इन्हीं वेदों का अंतिम भाग उपनिषद कहलाता है।  \n",
              "5  कश्मीर के तत्कालीन गवर्नर ने इस हस्तांतरण का व...  \n",
              "6   इसमें तुमसे पूर्व गुज़रे हुए लोगों के हालात हैं।  \n",
              "7   और हम होते कौन हैं यह कहने भी वाले कि वे गलत हैं  \n",
              "8  ग्लोबल वॉर्मिंग से आशय हाल ही के दशकों में हुई...  \n",
              "9  हो सकता है कि आप चाहते हों कि आप का नऋर्नमेनटे...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1ef77216-71da-4ba4-8c3a-aa4292ab5f12\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>english_sentence</th>\n",
              "      <th>hindi_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ted</td>\n",
              "      <td>politicians do not have permission to do what ...</td>\n",
              "      <td>राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ted</td>\n",
              "      <td>I'd like to tell you about one such child,</td>\n",
              "      <td>मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>indic2012</td>\n",
              "      <td>This percentage is even greater than the perce...</td>\n",
              "      <td>यह प्रतिशत भारत में हिन्दुओं प्रतिशत से अधिक है।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ted</td>\n",
              "      <td>what we really mean is that they're bad at not...</td>\n",
              "      <td>हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>indic2012</td>\n",
              "      <td>.The ending portion of these Vedas is called U...</td>\n",
              "      <td>इन्हीं वेदों का अंतिम भाग उपनिषद कहलाता है।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>tides</td>\n",
              "      <td>The then Governor of Kashmir resisted transfer...</td>\n",
              "      <td>कश्मीर के तत्कालीन गवर्नर ने इस हस्तांतरण का व...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>indic2012</td>\n",
              "      <td>In this lies the circumstances of people befor...</td>\n",
              "      <td>इसमें तुमसे पूर्व गुज़रे हुए लोगों के हालात हैं।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ted</td>\n",
              "      <td>And who are we to say, even, that they are wrong</td>\n",
              "      <td>और हम होते कौन हैं यह कहने भी वाले कि वे गलत हैं</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>indic2012</td>\n",
              "      <td>“”Global Warming“” refer to warming caused in ...</td>\n",
              "      <td>ग्लोबल वॉर्मिंग से आशय हाल ही के दशकों में हुई...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>tides</td>\n",
              "      <td>You may want your child to go to a school that...</td>\n",
              "      <td>हो सकता है कि आप चाहते हों कि आप का नऋर्नमेनटे...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1ef77216-71da-4ba4-8c3a-aa4292ab5f12')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1ef77216-71da-4ba4-8c3a-aa4292ab5f12 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1ef77216-71da-4ba4-8c3a-aa4292ab5f12');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNsHaTepmofc",
        "outputId": "3ff1c176-85a1-4a94-b163-683a12eea399"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 127607 entries, 0 to 127606\n",
            "Data columns (total 3 columns):\n",
            " #   Column            Non-Null Count   Dtype \n",
            "---  ------            --------------   ----- \n",
            " 0   source            127607 non-null  object\n",
            " 1   english_sentence  127605 non-null  object\n",
            " 2   hindi_sentence    127607 non-null  object\n",
            "dtypes: object(3)\n",
            "memory usage: 2.9+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing"
      ],
      "metadata": {
        "id": "LmeG76yKmspz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['english_sentence_mark'] = data['english_sentence'].apply(lambda x : '<sos> '+str(x)+' <eos>')\n",
        "data['hindi_sentence_mark'] = data['hindi_sentence'].apply(lambda x : '<sos> '+str(x)+' <eos>')"
      ],
      "metadata": {
        "id": "ctmbcneDmpez"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filters = '!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n'\n",
        "unk_token = '<unk>'"
      ],
      "metadata": {
        "id": "PjnaH9Ytmrlk"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenisation"
      ],
      "metadata": {
        "id": "CfB9bdJmsed4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "WsiR49TDmwHr"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorize_layer_en = tf.keras.layers.TextVectorization(\n",
        " output_mode='int',\n",
        " output_sequence_length=256)\n",
        "\n",
        "vectorize_layer_hi = tf.keras.layers.TextVectorization(\n",
        " output_mode='int',\n",
        " output_sequence_length=256)"
      ],
      "metadata": {
        "id": "6qYBvFbRmunL"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorize_layer_en.adapt(data['english_sentence_mark'])\n",
        "vectorize_layer_hi.adapt(data['hindi_sentence_mark'])"
      ],
      "metadata": {
        "id": "HTuZZvs9siZR"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ENCODER_LEN = 256\n",
        "DECODER_LEN = 256\n",
        "BATCH_SIZE = 10\n",
        "BUFFER_SIZE = BATCH_SIZE*4"
      ],
      "metadata": {
        "id": "HaZ_8VbxsjWx"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ENCODER_VOCAB  = len(vectorize_layer_en.get_vocabulary())\n",
        "DECODER_VOCAB = len(vectorize_layer_hi.get_vocabulary())"
      ],
      "metadata": {
        "id": "Pz8G332Eskah"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.Input(shape = (1,),dtype = tf.string),\n",
        "    vectorize_layer_en]\n",
        ")"
      ],
      "metadata": {
        "id": "xEjo-D9EskVw"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(data['english_sentence_mark']) == vectorize_layer_en(data['english_sentence_mark'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBzbUhVEsmYZ",
        "outputId": "5269ae30-e8e7-448a-9567-7481eecf2dee"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3988/3988 [==============================] - 10s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(127607, 256), dtype=bool, numpy=\n",
              "array([[ True,  True,  True, ...,  True,  True,  True],\n",
              "       [ True,  True,  True, ...,  True,  True,  True],\n",
              "       [ True,  True,  True, ...,  True,  True,  True],\n",
              "       ...,\n",
              "       [ True,  True,  True, ...,  True,  True,  True],\n",
              "       [ True,  True,  True, ...,  True,  True,  True],\n",
              "       [ True,  True,  True, ...,  True,  True,  True]])>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((vectorize_layer_en(data['english_sentence_mark']), vectorize_layer_hi(data['hindi_sentence']))).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "oMDAzgchsnho"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRANSFORMER"
      ],
      "metadata": {
        "id": "KFs00VpGsomw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_angles(position, i, d_model):\n",
        "    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
        "    return position * angle_rates\n",
        "\n",
        "def positional_encoding(position, d_model):\n",
        "    angle_rads = get_angles(\n",
        "        np.arange(position)[:, np.newaxis],\n",
        "        np.arange(d_model)[np.newaxis, :],\n",
        "        d_model\n",
        "    )\n",
        "\n",
        "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "\n",
        "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = angle_rads[np.newaxis, ...]\n",
        "\n",
        "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
        "\n",
        "def create_padding_mask(seq):\n",
        "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "    return seq[:, tf.newaxis, tf.newaxis, :]\n",
        "\n",
        "def create_look_ahead_mask(size):\n",
        "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "    return mask\n",
        "\n",
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "    matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
        "\n",
        "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "    if mask is not None:\n",
        "        scaled_attention_logits += (mask * -1e9)\n",
        "\n",
        "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
        "\n",
        "    output = tf.matmul(attention_weights, v)\n",
        "    return output, attention_weights"
      ],
      "metadata": {
        "id": "qjC0dN6psp75"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "\n",
        "        assert d_model % self.num_heads == 0\n",
        "\n",
        "        self.depth = d_model // self.num_heads\n",
        "\n",
        "        self.wq = tf.keras.layers.Dense(d_model)\n",
        "        self.wk = tf.keras.layers.Dense(d_model)\n",
        "        self.wv = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "        self.dense = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "    def split_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, v, k, q, mask):\n",
        "        batch_size = tf.shape(q)[0]\n",
        "\n",
        "        q = self.wq(q)\n",
        "        k = self.wk(k)\n",
        "        v = self.wv(v)\n",
        "\n",
        "        q = self.split_heads(q, batch_size)\n",
        "        k = self.split_heads(k, batch_size)\n",
        "        v = self.split_heads(v, batch_size)\n",
        "\n",
        "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
        "            q, k, v, mask)\n",
        "\n",
        "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "\n",
        "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
        "        output = self.dense(concat_attention)\n",
        "\n",
        "        return output, attention_weights"
      ],
      "metadata": {
        "id": "QrvAF3vRsrwR"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "    return tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(dff, activation='relu'),\n",
        "        tf.keras.layers.Dense(d_model)\n",
        "    ])"
      ],
      "metadata": {
        "id": "V9jSs98Rst3O"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "\n",
        "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x, training, mask):\n",
        "        attn_output,_ = self.mha(x, x, x, mask)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(x + attn_output)\n",
        "\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        out2 = self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "        return out2"
      ],
      "metadata": {
        "id": "dw3wjh3hsu6w"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "\n",
        "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "\n",
        "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
        "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)\n",
        "        attn1 = self.dropout1(attn1, training=training)\n",
        "        out1 = self.layernorm1(attn1 + x)\n",
        "\n",
        "        attn2, attn_weights_block2 = self.mha2(enc_output, enc_output, out1, padding_mask)\n",
        "        attn2 = self.dropout2(attn2, training=training)\n",
        "        out2 = self.layernorm2(attn2 + out1)\n",
        "\n",
        "        ffn_output = self.ffn(out2)\n",
        "        ffn_output = self.dropout3(ffn_output, training=training)\n",
        "        out3 = self.layernorm3(ffn_output + out2)\n",
        "\n",
        "        return out3, attn_weights_block1, attn_weights_block2"
      ],
      "metadata": {
        "id": "aXNnqjv1swVQ"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding, rate=0.1):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding, self.d_model)\n",
        "\n",
        "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x, training, mask):\n",
        "        seq_len = tf.shape(x)[1]\n",
        "\n",
        "        x = self.embedding(x)\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        x = self.dropout(x, training=training)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x = self.enc_layers[i](x, training, mask)\n",
        "\n",
        "        return x\n",
        "\n",
        "class Decoder(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, maximum_position_encoding, rate=0.1):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
        "\n",
        "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
        "        self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
        "        seq_len = tf.shape(x)[1]\n",
        "        attention_weights = {}\n",
        "\n",
        "        x = self.embedding(x)\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        x = self.dropout(x, training=training)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
        "\n",
        "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
        "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
        "\n",
        "        return x, attention_weights"
      ],
      "metadata": {
        "id": "kuB6-sZ2syQY"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_layers = 4\n",
        "d_model = 128\n",
        "dff = 128\n",
        "num_heads = 8\n",
        "dropout_rate = 0.1\n",
        "EPOCHS = 10"
      ],
      "metadata": {
        "id": "TDmu4vsLszgI"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(self, d_model, warmup_steps=4000):\n",
        "        super(CustomSchedule, self).__init__()\n",
        "\n",
        "        self.d_model = tf.cast(d_model, tf.float32)\n",
        "        self.warmup_steps = warmup_steps\n",
        "\n",
        "    def __call__(self, step):\n",
        "        step = tf.cast(step, tf.float32) # cast step to float32\n",
        "        arg1 = tf.math.rsqrt(step)\n",
        "        arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "metadata": {
        "id": "nVLNSGWBs1xQ"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = CustomSchedule(d_model)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"
      ],
      "metadata": {
        "id": "38TKSwJEs3lA"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "@tf.function\n",
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def accuracy_function(real, pred):\n",
        "    accuracies = tf.equal(real, tf.argmax(pred, axis=2))\n",
        "\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    accuracies = tf.math.logical_and(mask, accuracies)\n",
        "\n",
        "    accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
        "    mask = tf.cast(mask, dtype=tf.float32)\n",
        "    return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.Mean(name='train_accuracy')"
      ],
      "metadata": {
        "id": "6v2ZA59Ts5TI"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer = Transformer(\n",
        "    num_layers=num_layers,\n",
        "    d_model=d_model,\n",
        "    num_heads=num_heads,\n",
        "    dff=dff,\n",
        "    input_vocab_size=ENCODER_VOCAB,\n",
        "    target_vocab_size=DECODER_VOCAB,\n",
        "    pe_input=1000,\n",
        "    pe_target=1000,\n",
        "    rate=dropout_rate)"
      ],
      "metadata": {
        "id": "_XULYlK7s6Vg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_masks(inp, tar):\n",
        "    enc_padding_mask = create_padding_mask(inp)\n",
        "    dec_padding_mask = create_padding_mask(inp)\n",
        "\n",
        "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
        "    dec_target_padding_mask = create_padding_mask(tar)\n",
        "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "\n",
        "    return enc_padding_mask, combined_mask, dec_padding_mask"
      ],
      "metadata": {
        "id": "DySFUyTBs7cI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = \"checkpoints\"\n",
        "\n",
        "ckpt = tf.train.Checkpoint(transformer=transformer, optimizer=optimizer)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
        "\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "    print ('Latest checkpoint restored!!')"
      ],
      "metadata": {
        "id": "RAzqnngXs8uI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_step(inp, tar):\n",
        "    tar_inp = tar[:, :-1]\n",
        "    tar_real = tar[:, 1:]\n",
        "\n",
        "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions, _ = transformer(\n",
        "            inp, tar_inp,\n",
        "            True,\n",
        "            enc_padding_mask,\n",
        "            combined_mask,\n",
        "            dec_padding_mask\n",
        "        )\n",
        "        loss = loss_function(tar_real, predictions)\n",
        "\n",
        "    gradients = tape.gradient(loss, transformer.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "\n",
        "    train_loss(loss)\n",
        "    train_accuracy(accuracy_function(tar_real, predictions))"
      ],
      "metadata": {
        "id": "Z_CcvABSs90Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(text):\n",
        "    text = eng_tokenizer.texts_to_sequences([text])\n",
        "    text = tf.keras.preprocessing.sequence.pad_sequences(text, maxlen=ENCODER_LEN,\n",
        "                                                                   padding='post', truncating='post')\n",
        "\n",
        "    encoder_input = tf.expand_dims(text[0], 0)\n",
        "\n",
        "    decoder_input = [hind_tokenizer.word_index['<sos>']]\n",
        "    output = tf.expand_dims(decoder_input, 0)\n",
        "\n",
        "    for i in range(DECODER_LEN):\n",
        "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(encoder_input, output)\n",
        "\n",
        "        predictions, attention_weights = transformer(\n",
        "            encoder_input,\n",
        "            output,\n",
        "            False,\n",
        "            enc_padding_mask,\n",
        "            combined_mask,\n",
        "            dec_padding_mask\n",
        "        )\n",
        "\n",
        "        predictions = predictions[: ,-1:, :]\n",
        "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "\n",
        "        if predicted_id == hind_tokenizer.word_index['<eos>']:\n",
        "            return tf.squeeze(output, axis=0), attention_weights\n",
        "\n",
        "        output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "    return tf.squeeze(output, axis=0), attention_weights"
      ],
      "metadata": {
        "id": "c5iPPpjAtAGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translate(eng_text):\n",
        "    hind_text = evaluate(text=eng_text)[0].numpy()\n",
        "    hind_text = np.expand_dims(hind_text[1:], 0)\n",
        "    return hind_tokenizer.sequences_to_texts(hind_text)[0]"
      ],
      "metadata": {
        "id": "ET8kEMf9tByo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer,TFAutoModelForSeq2SeqLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-hi\")\n",
        "\n",
        "model = TFAutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-en-hi\",from_pt=True)"
      ],
      "metadata": {
        "id": "LeIpgsIMtDeI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tokenizer(data['english_sentence'][0],return_tensors=\"tf\").input_ids\n",
        "tokenizer.batch_decode(model.generate(input_ids=input_ids))"
      ],
      "metadata": {
        "id": "J00ER785tE3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['hindi_sentence'][0]"
      ],
      "metadata": {
        "id": "LPyXO3AstFzQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import datasets\n",
        "\n",
        "data_preprocess = datasets.Dataset.from_pandas(data.drop(['source','english_sentence_mark','hindi_sentence_mark'],axis = 1))"
      ],
      "metadata": {
        "id": "D4W4e-1ptGrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function(data):\n",
        "    inputs = list(map(str,data['english_sentence']))\n",
        "    targets = list(map(str,data['hindi_sentence']))\n",
        "    model_inputs = tokenizer(inputs, max_length=128, truncation=True)\n",
        "\n",
        "    # Set up the tokenizer for targets\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(targets, max_length=128, truncation=True)\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs"
      ],
      "metadata": {
        "id": "EW0ZfR9GtHli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets = data_preprocess.map(\n",
        "    preprocess_function,\n",
        "    batched=True,\n",
        "    remove_columns = ['english_sentence','hindi_sentence']\n",
        ")"
      ],
      "metadata": {
        "id": "T7VsNlnktJrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorForSeq2Seq\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"tf\")"
      ],
      "metadata": {
        "id": "Gqc2HqbetKqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out_data = tokenized_datasets.to_tf_dataset(\n",
        "    columns=[\"input_ids\", \"attention_mask\", \"labels\"],\n",
        "    collate_fn=data_collator,\n",
        "    shuffle=True,\n",
        "    batch_size=32,\n",
        ")"
      ],
      "metadata": {
        "id": "UKV1PYNAtLfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sacrebleu"
      ],
      "metadata": {
        "id": "IdXfYkSttMSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_metric\n",
        "\n",
        "metric = load_metric(\"sacrebleu\")"
      ],
      "metadata": {
        "id": "ysStJ3MLtNTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import create_optimizer\n",
        "from transformers.keras_callbacks import PushToHubCallback\n",
        "import tensorflow as tf\n",
        "\n",
        "# The number of training steps is the number of samples in the dataset, divided by the batch size then multiplied\n",
        "# by the total number of epochs. Note that the tf_train_dataset here is a batched tf.data.Dataset,\n",
        "# not the original Hugging Face Dataset, so its len() is already num_samples // batch_size.\n",
        "num_epochs = 3\n",
        "num_train_steps = len(out_data) * num_epochs\n",
        "\n",
        "optimizer, schedule = create_optimizer(\n",
        "    init_lr=5e-5,\n",
        "    num_warmup_steps=0,\n",
        "    num_train_steps=num_train_steps,\n",
        "    weight_decay_rate=0.01,\n",
        ")\n",
        "model.compile(optimizer=optimizer)\n",
        "\n",
        "# Train in mixed-precision float16\n",
        "tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")"
      ],
      "metadata": {
        "id": "4U9qYr8ntOso"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}